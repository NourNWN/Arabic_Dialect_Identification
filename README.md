# Arabic_Dialect_Identification

### Objectives of the Project:

1. Handling Arabic texts with multiple dialects.  
2. Understanding the challenges of dialect identification.  
3. Analyzing data to understand its content without reading it entirely.  
4. Cleaning and standardizing the text to prepare it for classification.  
5. Classifying texts using various vectorization methods and machine learning classification algorithms.  
6. Studying the impact of preprocessing techniques on the accuracy of the classification process.

Two datasets were used as follows:  

1. **MADAR Dataset**  
   You can refer to the official dataset website through the link, and you can download it from the provided link. This dataset includes phrases written in Arabic dialects from 25 Arab cities. It was constructed by translating each phrase in the dataset into 25 dialects (hence, this dataset is referred to as the "BTE Corpus" â€” a collection of parallel sentences).  
   Make sure to thoroughly read the dataset description to help you structure and understand the data effectively.  

2. **QADI Dataset**  
   Available at the provided link, this dataset was automatically collected from tweets. It encompasses a wide range of Arabic dialects across 18 different countries. The resulting dataset contains 540,000 tweets from 2,525 users distributed equally across the 18 Arab countries.  
